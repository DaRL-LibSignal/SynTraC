{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc999612-2caa-4d75-ac32-18ef0465a11d",
   "metadata": {},
   "source": [
    "# Calculate for Real world Dataset using different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d530acc4-e5dd-4c94-a525-6b331c5d3c15",
   "metadata": {},
   "source": [
    "## Pre-trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26053b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Model will be moved to GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/ASURITE/tchen169/anaconda3/envs/carla-prithvi/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/local/ASURITE/tchen169/anaconda3/envs/carla-prithvi/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/local/ASURITE/tchen169/anaconda3/envs/carla-prithvi/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/local/ASURITE/tchen169/anaconda3/envs/carla-prithvi/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=RetinaNet_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=RetinaNet_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: Faster R-CNN\n",
      "rmse results: 4.236744032862972\n",
      "mse results: 17.95\n",
      "mae results: 3.4\n",
      "Model Name: Mask R-CNN\n",
      "rmse results: 3.80460247594936\n",
      "mse results: 14.475\n",
      "mae results: 2.875\n",
      "Model Name: RetinaNet\n",
      "rmse results: 1.3133925536563698\n",
      "mse results: 1.725\n",
      "mae results: 0.975\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn, maskrcnn_resnet50_fpn, retinanet_resnet50_fpn, ssdlite320_mobilenet_v3_large\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
    "from math import sqrt\n",
    "import time\n",
    "\n",
    "with open('ground_truth.json', 'r') as file:\n",
    "\tground_dict = json.load(file)\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Model will be moved to GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Model will run on CPU.\")\n",
    "\n",
    "# Models to evaluate\n",
    "models = {\n",
    "    \"Faster R-CNN\": fasterrcnn_resnet50_fpn(pretrained=True),\n",
    "    \"Mask R-CNN\": maskrcnn_resnet50_fpn(pretrained=True),\n",
    "    \"RetinaNet\": retinanet_resnet50_fpn(pretrained=True),\n",
    "    #\"SSD\": ssdlite320_mobilenet_v3_large(pretrained=True),  # SSD variant from torchvision\n",
    "}\n",
    "\t\n",
    "# Load your image\n",
    "test_dataset_path = \"/home/local/ASURITE/tchen169/Documents/CV4TSC/rough/RL_Model/Arpit-Data/Dataset_collection/test_dataset/\"\n",
    "\n",
    "def save_detections_in_image(image_path, model, device):\n",
    "\t# Load and transform the image\n",
    "\timage = cv2.imread(image_path)\n",
    "\ttransform = transforms.Compose([transforms.ToTensor()])\n",
    "\timage_tensor = transform(image).to(device)\n",
    "\t\n",
    "\t# Get predictions from the model\n",
    "\twith torch.no_grad():\n",
    "\t\tprediction = model([image_tensor])\n",
    "\n",
    "\tvehicle_labels = [2, 3, 4, 6, 8]\n",
    "\t# Convert vehicle_labels list to a tensor and move it to the same device as the model's predictions\n",
    "\tvehicle_labels_tensor = torch.tensor(vehicle_labels).to(prediction[0]['labels'].device)\n",
    "\n",
    "\tif len(prediction) > 0:\n",
    "\t\tcar_indices = torch.isin(prediction[0]['labels'], vehicle_labels_tensor) & (prediction[0]['scores'] > 0.5)\n",
    "\t\tcar_boxes = prediction[0]['boxes'][car_indices].cpu().numpy()\n",
    "\t\t# print(len(car_boxes))\n",
    "\t\t\n",
    "\t\tfor box in car_boxes:\n",
    "\t\t\tx1, y1, x2, y2 = box.astype(int)\n",
    "\t\t\t# Draw bounding box\n",
    "\t\t\tcv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\t\n",
    "\t# Save the modified image\n",
    "\tinference_directory = \"/home/local/ASURITE/tchen169/Documents/CV4TSC/rough/RL_Model/Arpit-Data/Dataset_collection/inference_results/\"\n",
    "\tsave_path = os.path.join(inference_directory, os.path.basename(image_path))\n",
    "\tcv2.imwrite(save_path, image)\n",
    "\n",
    "\treturn len(car_boxes)\n",
    "\n",
    "# Evaluation loop\n",
    "for model_name, model in models.items():\n",
    "\ty_pred = []\n",
    "\ty_true = []\n",
    "\n",
    "\tmodel.eval()\n",
    "\tmodel.to(device)\n",
    "\tfor filename in os.listdir(test_dataset_path):\n",
    "\t\timg_path = os.path.join(test_dataset_path, filename)\n",
    "\t\tpredicted_output = save_detections_in_image(img_path, model, device)\n",
    "\t\t# print(f\"File: {os.path.basename(img_path)} detection: {predicted_output} GT {ground_dict[os.path.basename(img_path)]}\")\n",
    "\t\ty_pred.append(predicted_output)\n",
    "\t\ty_true.append(ground_dict[os.path.basename(img_path)])\n",
    "\tprint(\"Model Name:\", model_name)\n",
    "\tprint(\"rmse results:\",sqrt(mean_squared_error(y_true,y_pred)))\n",
    "\tprint(\"mse results:\",mean_squared_error(y_true,y_pred))\n",
    "\tprint(\"mae results:\",mean_absolute_error(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c38ff3",
   "metadata": {},
   "source": [
    "## Custom Model Trained on Carla Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "048b1967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Model will be moved to GPU.\n",
      "what is the epoch: 5\n",
      "Model Name: RetinaNet fine tuned on Carla and object detection model\n",
      "rmse results: 1.4053469322555197\n",
      "mse results: 1.975\n",
      "mae results: 0.975\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from functools import partial\n",
    "from torchvision.models.detection import RetinaNet_ResNet50_FPN_V2_Weights\n",
    "from torchvision.models.detection.retinanet import RetinaNetClassificationHead\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
    "from math import sqrt\n",
    "import time\n",
    "\n",
    "with open('ground_truth.json', 'r') as file:\n",
    "\tground_dict = json.load(file)\n",
    "\t\n",
    "\n",
    "def create_model(num_classes, model_path):\n",
    "    model = torchvision.models.detection.retinanet_resnet50_fpn_v2(\n",
    "        weights=RetinaNet_ResNet50_FPN_V2_Weights.COCO_V1\n",
    "    )\n",
    "    num_anchors = model.head.classification_head.num_anchors\n",
    "\n",
    "    model.head.classification_head = RetinaNetClassificationHead(\n",
    "        in_channels=256,\n",
    "        num_anchors=num_anchors,\n",
    "        num_classes=num_classes,\n",
    "        norm_layer=partial(torch.nn.GroupNorm, 32)\n",
    "    )\n",
    "    model_dict = torch.load(model_path)\n",
    "    model.load_state_dict(model_dict[\"model_state_dict\"])\n",
    "    print(\"what is the epoch:\",model_dict['epoch'])\n",
    "    return model\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Model will be moved to GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Model will run on CPU.\")\n",
    "\n",
    "# Models to evaluate\n",
    "models = {\n",
    "    # \"RetinaNet fine tuned on Carla\": create_model(2, model_path = \"/home/local/ASURITE/tchen169/Documents/CV4TSC/rough/RL_Model/Fine_Tuning_Model/outputs/best_model_backup2.pth\"),\n",
    "    \"RetinaNet fine tuned on Carla and object detection model\": create_model(2, model_path = \"/home/local/ASURITE/tchen169/Documents/CV4TSC/rough/RL_Model/Integrated_Fine_Tuning_Model/outputs/best_model.pth\")\n",
    "}\n",
    "\t\n",
    "# Load your image\n",
    "test_dataset_path = \"/home/local/ASURITE/tchen169/Documents/CV4TSC/rough/RL_Model/Arpit-Data/Dataset_collection/test_dataset/\"\n",
    "\n",
    "def save_detections_in_image(image_path, model, device):\n",
    "\t# Load and transform the image\n",
    "\timage = cv2.imread(image_path)\n",
    "\ttransform = transforms.Compose([transforms.ToTensor()])\n",
    "\timage_tensor = transform(image).to(device)\n",
    "\t\n",
    "\t# Get predictions from the model\n",
    "\twith torch.no_grad():\n",
    "\t\tprediction = model([image_tensor])\n",
    "\t# print(prediction)\n",
    "\n",
    "\tif len(prediction) > 0:\n",
    "\t\tcar_indices = (prediction[0]['scores']> 0.5).nonzero(as_tuple=True)[0]\n",
    "\t\tcar_boxes = prediction[0]['boxes'][car_indices].cpu().numpy()\n",
    "\t\t# print(len(car_boxes))\n",
    "\t\t\n",
    "\t\tfor box in car_boxes:\n",
    "\t\t\tx1, y1, x2, y2 = box.astype(int)\n",
    "\t\t\t# Draw bounding box\n",
    "\t\t\tcv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\t\n",
    "\t# Save the modified image\n",
    "\tinference_directory = \"/home/local/ASURITE/tchen169/Documents/CV4TSC/rough/RL_Model/Arpit-Data/Dataset_collection/inference_results/\"\n",
    "\tsave_path = os.path.join(inference_directory, os.path.basename(image_path))\n",
    "\tcv2.imwrite(save_path, image)\n",
    "\n",
    "\treturn len(car_boxes)\n",
    "\n",
    "# Evaluation loop\n",
    "for model_name, model in models.items():\n",
    "\ty_pred = []\n",
    "\ty_true = []\n",
    "\n",
    "\tmodel.eval()\n",
    "\tmodel.to(device)\n",
    "\tfor filename in os.listdir(test_dataset_path):\n",
    "\t\timg_path = os.path.join(test_dataset_path, filename)\n",
    "\t\tpredicted_output = save_detections_in_image(img_path, model, device)\n",
    "\t\t# print(f\"File: {os.path.basename(img_path)} detection: {predicted_output} GT {ground_dict[os.path.basename(img_path)]}\")\n",
    "\t\ty_pred.append(predicted_output)\n",
    "\t\ty_true.append(ground_dict[os.path.basename(img_path)])\n",
    "\tprint(\"Model Name:\", model_name)\n",
    "\tprint(\"rmse results:\",sqrt(mean_squared_error(y_true,y_pred)))\n",
    "\tprint(\"mse results:\",mean_squared_error(y_true,y_pred))\n",
    "\tprint(\"mae results:\",mean_absolute_error(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4aaa1aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10, 3, 3, 5, 2, 0, 4, 1, 10, 4, 2, 1, 2, 7, 0, 6, 0, 5, 2, 2, 1, 2, 2, 1, 1, 8, 4, 3, 4, 4, 0, 4, 1, 0, 3, 6, 2, 4, 5]\n",
      "[2, 12, 3, 4, 3, 4, 2, 4, 2, 12, 4, 1, 3, 3, 8, 0, 8, 0, 6, 2, 2, 1, 3, 3, 3, 0, 6, 4, 4, 3, 4, 2, 4, 1, 0, 4, 7, 2, 4, 10]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(y_true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
